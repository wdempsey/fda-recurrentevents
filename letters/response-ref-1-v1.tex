%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Plain Cover Letter
% LaTeX Template
%
% This template has been downloaded from:
% http://www.latextemplates.com
%
% Original author:
% Rensselaer Polytechnic Institute (http://www.rpi.edu/dept/arc/training/latex/resumes/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[11pt]{letter} % Default font size of the document, change to 10pt to fit more text

\usepackage{newcent} % Default font is the New Century Schoolbook PostScript font
%\usepackage{helvet} % Uncomment this (while commenting the above line) to use the Helvetica font

% Margins
\topmargin=-1in % Moves the top of the document 1 inch above the default
\textheight=8.5in % Total height of the text on the page before text goes on to the next page, this can be increased in a longer letter
\oddsidemargin=-10pt % Position of the left margin, can be negative or positive if you want more or less room
\textwidth=6.5in % Total width of the text, increase this if the left margin was decreased and vice-versa

\let\raggedleft\raggedright % Pushes the date (at the top) to the left, comment this line to have the date on the right
\usepackage{amsthm, amsfonts}
\usepackage{xcolor}
\usepackage{hyperref}


\def\Y{{\bf Y}}

\begin{document}

%----------------------------------------------------------------------------------------
%	ADDRESSEE SECTION
%----------------------------------------------------------------------------------------

\begin{letter}{Professor
	Peter Glynn\\
	Editor, {\em Journal of Applied Probability}}

%----------------------------------------------------------------------------------------
%	YOUR NAME & ADDRESS SECTION
%----------------------------------------------------------------------------------------

%\begin{center}
%\large
%\end{center}
%\vfill

\signature{Walter Dempsey\\
University of Michigan\\
Department of Biostatistics\\
1415 Washington Heights\\
Ann Arbor, MI 48103} % Your name for the signature at the bottom

%----------------------------------------------------------------------------------------
%	LETTER CONTENT SECTION
%----------------------------------------------------------------------------------------

\vspace{5mm}

\newpage

{\bf Response to Referees}

We appreciate all of the very helpful comments from the editor, associate editor, and the two referees which has helped improve the paper substantially. We have addressed the concerns as best as possible in this revision. We provide a further point-by-point explanation below. Any comments in {\it italics} indicate a statement from the referee report.

{\bf Response to Associate Editor}
\begin{enumerate}
\item {\it This paper was reviewed by two referees, who tend to agree in their positive assessments of the value and novelty of your work, and provide some very specific comments for further improvements.}

\vspace{5mm}
We thank the associate editor.  We have addressed the two reviewers' specific comments.  Responses to their concerns are detailed below and have significantly improved the clarify of this manuscript.   All major edits are highlighted in blue in order to help the referees know what has changed as part of the major revision.
\vspace{5mm}

\item {\it Expanded literature review on existing modeling approaches. Both referees raise this point, and I agree that the contrast with existing works could be more explicit. The second referee provides some specific suggestions on relevant works.}

\vspace{5mm}
We have added a detailed discussion of related work in Section 1.1, which includes the specific suggestions on relevant works provided by the second referee; specifically, we discuss recent modeling of time-to-event data with functional covariates as well as joint modelling from a functional regression perspective.  We contrast these approaches with our design-based approach which becomes necessary when considering high-frequency sensor processes rather than traditional longitudinal studies as the number of measurement occasions increase from tens to thousands/millions of times per individual.  We connect and contrast our use of subsampling with the general use of subsampling in handling massive data and its recent use in massive data with functional predictors.  As stated by the second referee, our proposed joint model includes a recent history functional linear model which we now link with the previous work by Damla Senturk and others.  This motivates Section XX which provides additional empirical study and discussion of the tuning parameter~$\Delta$.
\vspace{5mm}

\item {\it There appear to be some missing definitions of notation, and some transitions/equations need more details to justify them. The latter could potentially be put in the supplement to save space. The former should be added to the main manuscript to improve clarity.}

\vspace{5mm}
We have addressed the missing notation and helped to justify the transitions/equations.  These additions are highlighted in blue.
\vspace{5mm}

\item {\it As the first reviewer, I am confused by $\varepsilon(t) = 0$ on page 4, line 39, in line with equation (3) and measurement error methodology. I suspect comment 7 from the 2nd reviewer alludes to the same thing. I suspect this may be a notation issue rather than the modeling issue, but either way, it needs to be clarified.}

\vspace{5mm}
We have decided that the point we were trying to raise is non-essential to the current manuscript, so we have removed the discussion of \emph{independent evolution} and its implication that $\varepsilon (t) = 0$ for all $t >0$.  The key issue we were trying to clarify is that the traditional joint model formulation in which the observed health process and time-to-event are conditionally independent given the latent process implies that the hazard function conditional on the entire observed health process depends on values after the current time.  In the case study, for example, this implies that the expected risk of a button press given the entire sensor process will depend on future activity index and electrodermal activity.  This holds unless we assume the measurement error is set to zero.  While the author still thinks it an important point that he wishes was more well appreciated in the joint modeling literature, the current paper has enough content for this discussion to be omitted.  Moreover, the empirical impact seems to be limited and therefore it is better to make this point in a different manuscript and case study.
\vspace{5mm}

\item {\it Practical considerations, such as window size and smoothing parameter selection, need clarification.}

\vspace{5mm}
We added Section XX to discuss choice of window size; specifically, we consider selection based on Akaike information criteria as part of the simulation study rather than simply the impact of incorrect choice of $\Delta$. Figure XX shows that the adaptive tuning of $\Delta$ based on AIC does perofrm well empirically.  We now use this approach in selecting~$\Delta$ in the case study, and provide a plot of AIC across several choices of $\Delta$ in Figure XX in Appendix XX.
\vspace{5mm}

The smoothing parameter selection is also discussed in Section XX; given our connection to off-the-shelf penalized logistic regression, the smoothing parameter selection occurs as part of this implementation.  Therefore, we state how these are chosen generally in the software and provide some additional details in Appendix XX.
\vspace{5mm}

\item {\it Reviewer 2 suggests adding additional details on proof steps and lemma clarifications. I can't entirely agree that the proofs should go in the main manuscript as the paper is already on the longer side. When making adjustments to this section (theoretical analysis), please keep at most its current length, and move things to supplement as needed.}

\vspace{5mm}
To accommodate the second referee's request without making the discussion too long, we have added Remark XX and XX that provide some intuition.  We have re-written the technical proofs to first provide a sketch proof (with intuition) and then a detailed proof.  We hope this helps the reader develop intuition on the first read while giving them some helpful guidance in order to facilitate understanding of the detailed theoretical analysis.
\vspace{5mm}

\item {\it Both reviewers suggest additional simulation studies. I agree that it would be good to have a numerical benchmark of the magnitude of the computational issue that you allude to in lines 16-28 on page 5, especially for JCGS readership. I don’t think you need references for this, as the reviewer asks, as a numerical example would be more helpful and convincing in this case. However, I think you need another method for comparison, as the simulations are only done for your approach with different sampling rates. Perhaps some suggestions from the first referee could be useful. If some of these alternatives are computationally prohibitive, then doing a computational numerical comparison on even 1 rep will provide a convincing argument for why those methods are not tried.}

\vspace{5mm}
There does not exist a model that can do all so measures of bias and estimation accuracy may be inappropriate.  To handle this, we simply look at the average or the exponentially weighted where we can conceptualize it as a pre-processing step.  Then we can apply traditional joint models.  The issue is that the traditional jiont model cannot scale to this problem.  Instead, we
In Section XX, we perform the comparison in a simulation when compared to an unpenalized $K_x = 10$ linear spline model.  WE see that both are unbiased and our glmnet takes XX minutes while joint modeling took over XX hours.  To further this comparison, we perform a back-of-the-envelope calculation.
\vspace{5mm}

\item {\it I also have additional comments that were not raised. A major one is the absence of code. A user-friendly software with the method’s implementation and documentation is a must for accepted JCGS papers. Please provide the code so that the results are reproducible.}

\vspace{5mm}
We apologize for this omission.  Upon original submission, we had a GitHub repository that included both our code and documentation.  We did not cite the repository simply because other journals ask for anonymous submissions which means the GitHub link needs to be removed.  Given JCGS does not require this, we have now cited the repository in the Appendix.  The GitHub repository has been improved to include better documentation to ensure users of our proposed method can properly implement our solution on their own problems. Again we apologize for not correcting this before originally submitting the article. We think the revision now meets the standards of JCGS papers in terms of user-friendly software.
\vspace{5mm}

\item {\it
A minor one is the absence of truncation $K_x$ in the equation on line 37, page 8. Please reread everything carefully to ensure all notations are defined and the equations are consistent with the text.}

\vspace{5mm}
We apologize for this omission. We have reread everything and addressed any missing notation and equation consistency.
\vspace{5mm}

\item {\it Another minor one is your choice of smoothing the entire covariance, including the diagonals (page 8, lines 13-18). It’s unclear to me what the rationale is for changing this step compared to Park and Staicu, 2015, and how much it matters for the final performance.}

\vspace{5mm}
We have removed the discussion of \emph{independent evolution}.  While the author still thinks it an important point that he wishes was more well appreciated in the joint modeling literature, the current paper has enough content for this discussion to be omitted.  Therefore, we revert to the step from Park and Staicu (2018) and report the smoothing of the covariance matrix as it comes from their prior work.
\vspace{5mm}

\end{enumerate}

\newpage
{\bf Response to Referee \#1}
\vspace{5mm}

I am very grateful to the referee for the incredibly detailed review.  The detailed suggestions and comments helped improve the paper in numerous ways.  See below for our responses to each particular reviewer comment.

\begin{enumerate}
\item {\it The introduction it quite lacking. Please add more background literature review of prevailing/latest approaches (particularly in the area of joint modeling of longitudinal and time to event data) to the introduction.}

\vspace{5mm}
We have added a detailed discussion of related work in Section 1.1, which includes the specific suggestions on relevant works provided by the second referee; specifically, we discuss recent modeling of time-to-event data with functional covariates as well as joint modelling from a functional regression perspective.  We contrast these approaches with our design-based approach which becomes necessary when considering high-frequency sensor processes rather than traditional longitudinal studies as the number of measurement occasions increase from tens to thousands/millions of times per individual.  We connect and contrast our use of subsampling with the general use of subsampling in handling massive data and its recent use in massive data with functional predictors.  As stated by the second referee, our proposed joint model includes a recent history functional linear model which we now link with the previous work by Damla Senturk and others.  This motivates Section XX which provides additional empirical study and discussion of the tuning parameter~$\Delta$.
\vspace{5mm}

\item {\it The measurement error part can be added to the end with other exten-
sions. It does not seem to play a major role in developing the algorithm.}

\vspace{5mm}
We agree.  This point was over-emphasized in the original manuscript. We have decided that the point we were trying to raise is non-essential to the current manuscript, so we have removed the discussion of \emph{independent evolution} and its implications.
\vspace{5mm}

\item {\it In equationn (4), page 4, do you mean that equation (2) and the mesurement error part $x_i (t) = \eta_i (t) + \epsilon_i (t)$ imply conditional hazard equation in (3)?  If yes, then why is $\int_{t-\Delta}^t \epsilon_i (s) \beta(s) ds = 0$?  Or are you assuming a model?  Please add more clarity.}

\vspace{5mm}
We have now omitted this part from the current manuscript. The key issue we were trying to clarify is that the traditional joint model formulation in which the observed health process and time-to-event are conditionally independent given the latent process implies that the hazard function conditional on the entire observed health process depends on values after the current time.  In the case study, for example, this implies that the expected risk of a button press given the entire sensor process will depend on future activity index and electrodermal activity.  This holds unless we assume the measurement error is set to zero.  In this setting,~$\epsilon_i (t) = 0$ and so $\int_{t-\Delta}^t \epsilon_i (s) \beta(s)ds = 0$ by definition. While the author still thinks it an important point that he wishes was more well appreciated in the joint modeling literature, the current paper has enough content for this discussion to be omitted.  Moreover, the empirical impact seems to be limited and therefore it is better to make this point in a different manuscript and case study.
\vspace{5mm}

\item {\it Several notations in section 2.1 such as ${\bf x}_i, {\bf H}_{i,\tau_i}^X$ are not defined.}

\vspace{5mm}
Both of these were defined in Section 3 but we agree that the definitions were obscured in the writing, which led to confusion.  To address this, we have added a notation glossary as Appendix XX.
\vspace{5mm}

\item {\it How did you get the equation in line 24, page 4.}

\vspace{5mm}
We believe the referee is referring to the log-likelihood related to the event process.   Conditional on the sensor process over the observation window $[0,\tau_i]$, i.e.,~$\{ x_i (t) \}_{t=0}^{\tau_i}$, we define the conditional intensity according to equation (2).  Then the probability of the observed event times per person follows from $\exp \left( - H_i (\tau_i ; \theta) \right) \prod_{j=1}^{k_i} h \left(T_{i,j};\theta \right)$.  Thus the log-likelihood of the even process is given by $L_n (\theta)$.
\vspace{5mm}

\item {\it In line 39, page 4, by assuming $\epsilon(t) = 0$, you assume there is no measurement error? Why is section 2.1 called measurement error if the error is 0? Should this be named missing data section instead?}

\vspace{5mm}
The key point raised on page 4 (now in Appendix XX), is that if $\epsilon(t)$ is not equivalently zero, your model assumes risk of an event at time $t$ depends on both the current and future measurements of the process ${\bf x}_i$. We argue this is not sensible since current risk should not depend on future risk and thus set $\epsilon(t) = 0$.
\vspace{5mm}

\item  {\it Is $\theta$ defined anywhere prior to section 2.2?}

\vspace{5mm}
It was used in equation (1) to refer to all the parameters underlying the model to distinguish it from the functional parameter~$\beta (s)$. We have added a notation glossary in Appendix XX, and re-iterate its definition in Section 3 to make this clearer.
\vspace{5mm}

\item {\it On page 5, lines 16 - 28 you claim that computing the double integral is computationally expensive. Add some references. Also, to give a greater insight to the extent of the computational cost, solve the score equation in lines 8,9 i.e. without the sub-sampling framework in the simulations (there is another comment on this for the simulation section). Reporting a rough summary of computational cost such as ” it took x min to solve equations involving n samples” here, would help the reader understand
the extent of the problem.}

\vspace{5mm}
We have added Remark XX and Section XX in the simulation study to give additional details and empirical evidence. First, there are two areas where we have computational improvements.  First, in the inner integral, we have

Second, even if we have computed $\int_{t-\Delta} x(t-s)\beta(s) ds$
We explain that if we were to compute it would have to be as a function of $\beta(s)$.  We implement a naive and demonstrate numerically the computational cost.  Specifically, each computation in simulation takes XXseconds, and we must compute this XX times to compute the likel
\vspace{5mm}

\item {\it Page 5, line 51, what is $t_i$?}

\vspace{5mm}
This should be $\tau_i$ which is the censoring time of the observation process for individual~$i$.
\vspace{5mm}

\item {\it Check the notation in equation (6) page 6. Some subscripts seem to be missing. Add some details on how to obtain this from the original score
equation. What is the approximation here?}

\vspace{5mm}
We have included correct subscripts in the revision.  Derivation of (6) follows from plugging in (4) into equation the score equations.  We now make this clear and provide a derivation in the supplementary materials for completeness.
\vspace{5mm}

\item{\it The remark 2.1 can be added the end of section 2.2. This along with
comment 8 will naturally lead the way your proposed method.}

\vspace{5mm}
We thank the referee for this suggestion.  We have now used Remark 2.1 and comment 8 on the computational costs to the end of section 2.2 to motivated our proposed method.
\vspace{5mm}

\item {\it Page 7, line 48, in the definition of the marginal covariance, it should be $dT$ in the integral.}

\vspace{5mm}
That is correct.  We have fixed the definition as suggested.
\vspace{5mm}

\item {\it Page 7, line 48, in the definition of the marginal covariance, what is $\tau$?}

\vspace{5mm}
The term $\tau$ refers to the censoring time of the observation process. We make this clear in Section XXX, page XX in the revision.
\vspace{5mm}


\item {\it Is there a difference between the mean and covariance functions for $y = 0$ and $y = 1$ especially if points in $D_i$ and $T_i$ are spread roughly evenly on a grid even if the sets are disjoint? For example, pick a grid of equidistant points and number them from $1-10$. If all odd points are events in $T_i$ and even ones are sampled in $D_i$, won't the pooled sample covariance for both be the same}

\vspace{5mm}
The event times~$T_i$ depend heavily on the event intensity function~$h_i (t;\theta)$ and will not be guaranteed to be uniformly spread across points in $[0,\tau]$.  The subsampling times~$D_i$ depend on the subsampling intensity function~$\pi_i(t)$ and

We also now clarify that the missing data imputation from XXXX requires distinct covariance functions and thus we keep as is.  We do think one could marginalize across the two if the mean and covariance functions aren't expected to differ greatly and state as such in Section XX (in blue).
\vspace{5mm}

\item {\it Add a plot of the mean, covariance functions for $y=0$ and $y=1$.}

\vspace{5mm}
We have added mean and covariance functions to the supplementary materials as suggested.  The plots demonstrate distinct behavior in the means for $y=0$ and $y=1$; while the covariance functions are XXXX.
\vspace{5mm}

\item {\it Page 9, line 6, isn’t the integral in (2) $\int_{t-\Delta}^t X(s) \beta(s)ds$? The whole development assumes the integral to be $\int_{t-\Delta}^t X(t-s) \beta(s)ds$. The interpretation of the coefficient function $\beta()$ would be different for two cases. Please clarify.}

\vspace{5mm}
We apologize for the confusion.  In Section 3.1, we started by defining the double-indexed $X(t,s)$ to be equal to $X(t-s)$ in order to make the notation a bit cleaner but we see that this has added confusion.  We not add a remark to make this more clear.  The reason for the notation was that writing $X(t,s)$ allows us to write the integrals over $0$ to $\Delta$ rather than having to constantly index integrals by $t$.  Moreover, we thought it helps the reader to understand we are saying ``the process $s$ units prior to time~$t$.''
\vspace{5mm}

\item {\it Page 9, equation 7, please define all of the notations before using them.}

\vspace{5mm}
We have re-written this paragraph to first define the notation and then present equation (7).
\vspace{5mm}

\item {\it Page 12, line 48, what is proposition 3.6? You mean Lemma?}

\vspace{5mm}
That is correct, we have fixed this issue.
\vspace{5mm}

\item {\it When are the assumptions satisfied or not satisfied? An example of a
situation where the functional and event process assumptions are easily satisfied will be useful.}

\vspace{5mm}
We have shown that the functional process satisfies these moment conditions under boundedenss which is
\vspace{5mm}

\item {\it All the modes of convergences in Lemma 3.5 and its proofs should be made clear.}

\vspace{5mm}
XXXxXX
\vspace{5mm}

\item {\it Outline the proof of Lemma 3.5 first and then prove the details.  It will be easier to follow.  Alternatively, we }

\vspace{5mm}
We have added a sketch of the proof with an outline as part of the supplementary details.
\vspace{5mm}

\item {\it In Lemma 3.6 state the theorem clearly.  What condition do yu show in the proof that establishes optimality}

\vspace{5mm}
We have now included the statement of how we define optimality in the main paper to make the theorem statement clear.  Proof is kept in the supplementary materials for conciseness.
\vspace{5mm}

\item {\it Combine section 3.6 and 3.7 in to a single result that establishes a confidence band for $\beta (t)$. Also, wont Lemma 3.5 lead to a confidence band for $\hat \beta (t)$? Are the two bands same?}

\vspace{5mm}
We discuss the penalization due to the potential complexity of the.  The confidence bands are based on Lemma 3.5.  We make this clear in the revision.  The issues are still thre and we keep the discussion.  We keep as 2 separate sections since they cover different issues.
\vspace{5mm}

\item The ``original'' score equation Page 5, line 9 involves
$$
H_i (\tau_i ;\theta) = \int_{t=0}^{\tau_i} h_i (t; \theta)dt = \int_0^{\tau_i} \left[ h_0 (t;\gamma) \exp \left( g_t (H_{i,t}^N)^\top \alpha + \int_{s=t-\Delta}^t x_i (s) \beta(t) ds \right) \right] dt
$$
In the subsampled version you suggest in equation 6, page 6, you essentially replace $H_i (\tau_i; \theta)$ computation with $h_i (u; \theta)$, $u \in D_i$. How much time would it take to solve the full likelihood equation that will involve the above equation (1) directly? With the basis expansion strategy, you
would will be estimating the same number of parameters. This type of approach should be added to simulations and evaluated for accuracy and time complexity.

\vspace{5mm}
XXXXX
\vspace{5mm}

\item {\it How about using a concurrent model for $h_i (t;\theta) = h_0 (t; \theta) \exp (g_t (H_{i,t}^N)^\top \alpha + x_i (t) \beta (t))$. This does not look at the past window like the suggested model but this drawback might be compensated with the constructed features $g_t (H_{i,t}^N)$ that capture the past. The concurrent approach might be much less expensive computationally. This can be added as an alternative to the simulations.}

\vspace{5mm}
XXXXX
There is no obvious way to compute bias since the model will be incorrectly specified.  We do show the computation trade-off and that computing the cumulative hazard is still computationally demanding; therefore, after sampling non-event times, the added computation of the interior integral is not very expensive and avoids model misspecification.
\vspace{5mm}

\item {\it In section 5.2.1 what is uncongeniality? Does it have a mathematical
meaning?}

\vspace{5mm}
uncongenial comes from Meng. We cite and provide a short formal definition with some intuition.
\vspace{5mm}

\item Page 23, Figure 2. EDA seems to spike at the end. Even AI seems to be
turning up. Add longer history to both the Figures.


\item {\it Doesn’t Figure 3 suggest smaller $\Delta$?}

\vspace{5mm}
We agree.  We re-run the analysis with a window length of 15 minutes as well and move the current analysis as a sensitivity to the supplementary materials.
\vspace{5mm}

\item {\it What features were constructed for the real data analysis?}

\vspace{5mm}
As this was illustrative we only included time-of-day.
\vspace{5mm}


\end{enumerate}

\newpage

{\bf Response to Referee \#2}

I am incredibly grateful for this review.  I am very happy that the referee found that this paper makes a nice contribution to the field of functional data; we, of course, agree. The application was what drove this methodology so we are also happy to hear that the referee found the application interesting. We next address the reviewers specific comments.

\begin{enumerate}
\item {\it There exists a good amount of recent efforts modeling event data with functional data predictor or joint modeling, so a literature review on relevant papers would be useful. See, for example, papers by Dr. Ciprian Crainiceanu from Johns Hopkins, Dr. Sheng Luo from Duke, and Dr. Jiguo Cao from Simon Fraser.}

\vspace{5mm}
XXXXXX.
We added Section XX to describe the related work and connect our methodology to the existing literature.
\vspace{5mm}

\item {\it It might be worth mentioning existing literature on historical functional linear models, e.g., papers by Dr. Damla Senturk from UCLA and collaborators.}

\vspace{5mm}
XXXXXX.
We added Section XX to describe the related work and connect our methodology to the existing literature.
\vspace{5mm}

\item {\it As with any recent history functional linear models, the size of the window ($\Delta$) is an important parameter. So it would be helpful to see some efforts on developing a data-adaptive method for the selection of $\Delta$.}

\vspace{5mm}
XXXXXX
\vspace{5mm}

\item {\it While in Section 3.6 the paper discusses penalized functional regression to reduce overfitting, it is unclear if the paper actually adopts it in simulation studies and application. It is of interest how the smoothing parameter is selected. My concern is that if no penalty is employed, with more than 30 basis functions, overfitting can be severe and much wider confidence bands are often obtained}

\vspace{5mm}
XXXXXX
\vspace{5mm}

\item {\it While in Section 3.6 the paper discusses penalized functional regression to reduce overfitting, it is unclear if the paper actually adopts it in simulation studies and application. It is of interest how the smoothing parameter is selected. My concern is that if no penalty is employed, with more than 30 basis functions, overfitting can be severe and much wider confidence bands are often obtained}

\vspace{5mm}
XXXXXX
\vspace{5mm}

\item {\it In the theoretical section, it would be helpful to understand what intermediate results Assumption 3.4 will lead to.}

\vspace{5mm}
XXXXXX
\vspace{5mm}

\item {\it In the simulation study, it would make sense to me consider a coefficient function for which the magnitude is not only decaying further away from current time and also becomes 0 at $t-\Delta$. In addition, it might be helpful to use relative errors to quantify the accuracy of estimation of coefficient functions.}

\vspace{5mm}
XXXXXXX
\vspace{5mm}

\item {\it Section 2.1 discusses the rationale of modeling functional predictor without noises. Note that the proposed methodology is actually suitable for data with noises. First, the data application seems to suggest noises are indeed present; see Figure 2 (A). Second, I am not sure I fully understand why in the equation after (3), the conditional probability is conditioning on functional predictor observed up to censoring or truncation time. Isn’t it more sensible to condition on functional predictor observed up to t? Then, the conditional probability will not depend on functional predictor beyond time t.}

\vspace{5mm}
The model is under conditional independence $\eta$.
\vspace{5mm}


\item {\it In Section 3.1, the paper considers modeling the mean function separately at event times and non-event times. Is there some reasoning or justification for this?}

\vspace{5mm}
Separate models in FACE paper so we can use the ; however, it makes minimial difference.  So we cite this.
\vspace{5mm}

\item {\it Minor comments: there are typos and inconsistent naming in the paper, e.g., Proposition 3.6 should actually be Lemma 3.6, AI and ACC are used to refer to activity index.}

\vspace{5mm}
We apologize for the typos and inconsistent naming.  This has been resolved.
\vspace{5mm}

\end{enumerate}


\end{letter}






\end{document}





